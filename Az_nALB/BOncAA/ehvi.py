# -*- coding: utf-8 -*-
"""Multi_objective.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iaZZFU-4FD7kQ2b9wRzgWYr-HZ73q66U

# Workflow:
## Goal: Optimize (minimize) the ddG or REU value for a single ncaa incorporation
### Input Parameter: Sequence position, 3d coordinate position, Avoid coordinate positions
### Optimization function: Rosetta Mutate and Relax protocol
### Acquisition: Sequence position (distant on a 1D level), 3d coordinate position(distant on a 3D level), Avoidance positions (distance on a 3D level from binding), Surface exposure
"""

'''Imports'''
import warnings
warnings.filterwarnings("ignore")
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))
from rosetta import *
from pyrosetta import *
from pyrosetta.rosetta.protocols.interface import select_interface_residues
from RncAAM.mutationscoring import g_chillaxer
from RncAAM.example import Mutation_Wrapper
from prep import coordinates, find_binding_region, binding_coordinates, distance_to_region, get_coordiantes, get_surface_exposures
import torch
from botorch.acquisition.objective import GenericMCObjective
from botorch.sampling.samplers import SobolQMCNormalSampler
from botorch.optim.optimize import optimize_acqf_list
from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement
from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization
import numpy as np
from botorch.utils.sampling import sample_simplex
path = '../Parameters'
init(f'-extra_res_path {path} -mute all -constant_seed');

"""# Input Preparations

"""

protein_path = '../BOncAA/nALBbound.pdb'
complexed = pose_from_file(protein_path)
target_chain_letter = 'A'
#complexed = g_chillaxer(complexed, target_chain_letter)

'''Get the sequence (1D representation of the protein)'''
target = Pose()
target_chain = complexed.split_by_chain()[2]
target.assign(target_chain)

target_range = range(1, len(target.sequence())+1)
print(len(target_range))

cystine_free = []
for i in range(1, len(target_range) +1):
    residue = target.residue(i)
    if residue.name() == 'C' or residue.name() == 'CYS:disulfide':
        print(f'removed residue {i}')
        continue
    else:
        cystine_free.append(i)
target_range = cystine_free
print(get_surface_exposures(target, target_range))

'''Prep all BO Inputs / Search Domain'''
coords = coordinates(target)
binding_region, nonbinding_region =find_binding_region(complexed, target_chain_letter=target_chain_letter)
b_coordinates, nb_coordinates = binding_coordinates(complexed, binding_region)
# d_to_binding = distance_to_binding(b_coordinates, nb_coordinates)

"""# Bayesian Optimization

"""

def objective(complexed_pose, chain, position, ncaa, smiles, radius_relax = 7,
              trials = 3, mutationrelx = True, mutation_dump = True):
    return(Mutation_Wrapper(complexed_pose, chain, position, ncaa, smiles, radius_relax = radius_relax,
                            trials = trials, mutationrelx = mutationrelx, mutation_dump = mutation_dump))

import math
from typing import Optional

from botorch.acquisition.monte_carlo import MCAcquisitionFunction
from botorch.models.model import Model
from botorch.sampling.base import MCSampler
from botorch.sampling.normal import SobolQMCNormalSampler
from botorch.utils import t_batch_mode_transform
from torch import Tensor


import math
from typing import Optional

from botorch.acquisition.monte_carlo import MCAcquisitionFunction
from botorch.models.model import Model
from botorch.sampling.base import MCSampler
from botorch.sampling.normal import SobolQMCNormalSampler
from botorch.utils import t_batch_mode_transform
from torch import Tensor

# Import EHVI and related utilities
from botorch.acquisition.multi_objective import qExpectedHypervolumeImprovement
from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement
from botorch.utils.multi_objective.hypervolume import Hypervolume
from botorch.utils.multi_objective.box_decompositions.dominated import DominatedPartitioning
from botorch.utils.transforms import unnormalize
from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective


complexed_pose = complexed
chain = target_chain_letter
ncaa = 'NAT'
smiles = 'tester'

from botorch.models import SingleTaskGP, ModelListGP
from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood
from botorch.fit import fit_gpytorch_mll


iterations = 5



def bayesian_optimization(objective, binding_coordinates, target_range, iterations, complexed, target,
                          chain, ncaa, smiles, radius_relax=7, trials=3,
                          mutationrelx=True, mutation_dump=True, random_seed = None):
    """
    Bayesian optimization using EHVI acquisition function
    """
    np.random.seed(random_seed)
    possible_positions = np.array(target_range)
    np.random.shuffle(possible_positions)
    initial_positions = possible_positions[:2]

    print(f'Initial positions selected:{initial_positions}')
    inital_observations = []
    for position in initial_positions:
        print(f'Processing Position: {position}')
        inital_observations.append(objective(
            complexed, chain, [int(position)],
            ncaa, smiles, radius_relax=radius_relax,
            trials=trials, mutationrelx=mutationrelx,
            mutation_dump=mutation_dump
        ))
        print(f'Finished position: {position}')

    
    evaluated = torch.tensor(np.array(initial_positions, dtype=np.float64)).unsqueeze(-1)
    observations = torch.tensor(np.array(inital_observations, dtype=np.float64))
    
    # For EHVI, we need the observations in the right shape [n_points, n_objectives]
    if observations.dim() == 1:
        observations = observations.unsqueeze(-1)

    for i in range(iterations):
        models = []
        for j in range(observations.shape[-1]):
            obs = observations[:, j].unsqueeze(-1)
            models.append(
                SingleTaskGP(evaluated, obs)
            )

        model = ModelListGP(*models)
        mll = SumMarginalLogLikelihood(model.likelihood, model)

        fit_gpytorch_mll(mll)

        evaluated_flat = evaluated.squeeze().tolist()
        mask1 = [pos not in evaluated_flat for pos in target_range]
        unevaluated = torch.tensor(np.array(target_range)[mask1], dtype=torch.float64)

        evaluated_coordinates = get_coordiantes(target, evaluated)
        unevaluated_coordinates = get_coordiantes(target, unevaluated)

        # Set up reference point (should be worse than all observed points)
        # For minimization problems, ref_point should be larger than all observations
        with torch.no_grad():
            pred = model.posterior(unevaluated).mean
        weights = sample_simplex(2).squeeze()
        objective = GenericMCObjective(
            get_chebyshev_scalarization(
                weights,
                pred
            )
        )
        sampler = SobolQMCNormalSampler(num_samples=MC_SAMPLES)
        acquisition = qNoisyExpectedImprovement(
            model=model,
            objective = objective, 
            sampler = sampler, 
            X_baseline=evaluated, 
            prune_baseline = True, 
        )
        acq_fun_list = [acquisition]
        chosen_point, _ = optimize_acqf_list(
            acq_function_list=acq_fun_list,
            bounds=standard_bounds,
            num_restarts=NUM_RESTARTS,
            raw_samples=RAW_SAMPLES,
            options={
                "batch_limit": 5,
                "maxiter": 200,
            }
        )  
        #chosen_point = unevaluated[nominated_point].item()

        print(f'chosen_point: {chosen_point}')
        print(f'Next position to be evaluated: {chosen_point}')
        
        new_observation = objective(
            complexed, chain, [int(chosen_point)],
            ncaa, smiles, radius_relax=radius_relax,
            trials=trials, mutationrelx=mutationrelx,
            mutation_dump=mutation_dump
        )
        
        evaluated = torch.cat((evaluated, torch.tensor([[chosen_point]], dtype=torch.float64, **tkwargs)))
        new_obs_tensor = torch.tensor(new_observation, dtype=torch.float64, **tkwargs)
        if new_obs_tensor.dim() == 1:
            new_obs_tensor = new_obs_tensor.unsqueeze(0)
        observations = torch.cat((observations, new_obs_tensor))

        print(f"Iteration {i+1}: Best value = {observations.min().item()}, "
              f"Acquisition = {acq_values[nominated_point].item()}")

    return evaluated, observations


# Run optimization with EHVI

import pandas as pd

all_results = []  # list to collect all trial results

for i in range(5):
    evaluated, observations = bayesian_optimization(
        objective,
        b_coordinates,
        target_range,
        2,
        complexed,
        target,
        chain,
        ncaa,
        smiles,
        radius_relax=7,
        trials=1,
        mutationrelx=False,
        mutation_dump=False,
        random_seed=i
    )

    evaluated = np.array(evaluated.cpu(), dtype=int)
    observations = np.array(observations.cpu())

    # Create a DataFrame for this run and store run index
    df = pd.DataFrame({
        "Run": i,
        "Points Evaluated": evaluated,
        "Binding ddG": observations[:, 0],
        "Folding ddG": observations[:, 1]
    })

    all_results.append(df)

# Concatenate all runs into one DataFrame
final_df = pd.concat(all_results, ignore_index=True)

# Save one CSV with all runs
final_df.to_csv("08_13_BayesOpt_EHVI_15runs_all.csv", index=False)

